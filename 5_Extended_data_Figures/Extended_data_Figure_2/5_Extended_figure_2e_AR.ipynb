{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "successful-allergy",
   "metadata": {},
   "source": [
    "# Extended Figure 2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import rpy2\n",
    "import seaborn as sns\n",
    "\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.settings.set_figure_params(dpi=300, dpi_save=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = sc.read('/nfs/team298/ar32/YS_citeseq_submission_1_anndata_objects/cite_seq_protein_simple_processed_for_submission_20220407.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(protein, color='broad_anno', size=8, save='protein_umap_broad_anno_20220406.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_env_Hlab",
   "language": "python",
   "name": "python_env_hlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
