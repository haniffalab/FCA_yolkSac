{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib as mpl\n",
    "import gseapy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import decomposition\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "import ppscore as pps\n",
    "import pathlib\n",
    "import os\n",
    "sc.settings.set_figure_params(dpi=80,dpi_save=300, color_map='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read('/home/jovyan/YS_project/YS/Data_objects/final_objects/A4_V7_YS_integrated_data_singlets_with_raw_counts_for_MS_plotting_20211111_with_obsp.h5ad')\n",
    "\n",
    "dict1 = {\n",
    "'CS10' : 'CS10-11',\n",
    "'CS11' : 'CS10-11',\n",
    "'CS14' : 'CS14-15',\n",
    "'CS15' : 'CS14-15',\n",
    "'CS18' : 'CS18',\n",
    "'CS22' : 'CS22-23',\n",
    "'CS23' : 'CS22-23'\n",
    "}\n",
    "\n",
    "adata.obs['time_points'] = adata.obs['stage'].map(dict1)\n",
    "\n",
    "# macrophage, erythroid, endoderm\n",
    "mac_csv = pd.read_csv('/home/jovyan/YS_project/YS/YS_check_ealy_vs_late_csvs/sig_FC_early_late_neighbourhoods/Macrophage_sig_fc_early_late.csv', index_col = 1)\n",
    "eryth_csv = pd.read_csv('/home/jovyan/YS_project/YS/YS_check_ealy_vs_late_csvs/sig_FC_early_late_neighbourhoods/Erythroid_sig_fc_early_late.csv', index_col = 1)\n",
    "endo_csv = pd.read_csv('/home/jovyan/YS_project/YS/YS_check_ealy_vs_late_csvs/sig_FC_early_late_neighbourhoods/Endoderm_sig_fc_early_late.csv', index_col = 1)\n",
    "\n",
    "#mac_csv = mac_csv[~mac_csv['nhood_Sig_FC'].str.match('False')]\n",
    "#eryth_csv = eryth_csv[~eryth_csv['nhood_Sig_FC'].str.match('False')]\n",
    "#endo_csv = endo_csv[~endo_csv['nhood_Sig_FC'].str.match('False')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_index = list(adata.obs.index)\n",
    "\n",
    "n = 0\n",
    "data_names = ['mac_csv','eryth_csv','endo_csv']\n",
    "\n",
    "for i in [mac_csv,eryth_csv,endo_csv]:\n",
    "    index_list = i.index[i.index.str.contains('Wang')]\n",
    "    diff = list(set(index_list).difference(adata_index))\n",
    "    for index in diff:\n",
    "        i = i.rename(index={index: index+'_1'})\n",
    "    index_list = i.index[i.index.str.contains('Wang')]\n",
    "    intersect = (set(adata_index) & set(index_list))\n",
    "    if len(intersect) == len(index_list):\n",
    "        name = data_names[n]\n",
    "        globals()[name] = i\n",
    "        n +=1\n",
    "        pass\n",
    "    else:\n",
    "        diff = list(set(index_list).difference(adata_index))\n",
    "        for index in diff:\n",
    "            i = i.rename(index={index: index+'_2'})\n",
    "        index_list = i.index[i.index.str.contains('Wang')]\n",
    "        intersect = (set(adata_index) & set(index_list))\n",
    "        if len(intersect) == len(index_list):\n",
    "            globals()[name] = i\n",
    "            n +=1\n",
    "            pass\n",
    "        else:\n",
    "            raise Exception(f'Error in barcode inetersect on loop {n}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "macrophage = adata[adata.obs.index.isin(list(mac_csv.index))][:]\n",
    "erythroid = adata[adata.obs.index.isin(list(eryth_csv.index))][:]\n",
    "endoderm = adata[adata.obs.index.isin(list(endo_csv.index))][:]\n",
    "\n",
    "macrophage.obs['nhood_Sig_FC'] = mac_csv['nhood_Sig_FC'][mac_csv.index.isin(list(macrophage.obs.index))]\n",
    "erythroid.obs['nhood_Sig_FC'] = eryth_csv['nhood_Sig_FC'][eryth_csv.index.isin(list(erythroid.obs.index))]\n",
    "endoderm.obs['nhood_Sig_FC'] = endo_csv['nhood_Sig_FC'][endo_csv.index.isin(list(endoderm.obs.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = [macrophage,erythroid,endoderm]\n",
    "\n",
    "for i in objects:\n",
    "    i.obs['early_late_time_points'] = i.obs['nhood_Sig_FC'].astype(str) + '_' + i.obs['time_points'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "endoderm = endoderm[~endoderm.obs['early_late_time_points'].isin(['Late_CS14-15']),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [macrophage,endoderm]\n",
    "names = ['Macrophage','Endoderm']\n",
    "orig_name = ['macrophage','endoderm']\n",
    "n = 0\n",
    "\n",
    "for i in datas:\n",
    "    name = names[n]\n",
    "    temp_data = adata[adata.obs['broad_cell_labels_organ'].isin([name+'_ys'])]\n",
    "    temp_data = temp_data[temp_data.obs['stage'].isin(['CS22','CS23'])]\n",
    "    datas = [i,temp_data]\n",
    "    new_data = sc.AnnData.concatenate(*datas, join='inner', batch_categories=None ,index_unique=None)\n",
    "    del new_data.obs['batch']\n",
    "    old_name = orig_name[n]\n",
    "    globals()[old_name] = new_data\n",
    "    n+=1\n",
    "\n",
    "macrophage.obs.loc[macrophage.obs['time_points'].isin(['CS22-23']),['nhood_Sig_FC','early_late_time_points']] = ['Late','Late_CS22-23']\n",
    "endoderm.obs.loc[endoderm.obs['time_points'].isin(['CS22-23']),['nhood_Sig_FC','early_late_time_points']] = ['Late','Late_CS22-23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = [macrophage,erythroid,endoderm]\n",
    "objects_name = ['macrophage','erythroid','endoderm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_cycle_genes = pd.read_csv('/home/jovyan/Useful code and scripts/issac_cell_cycle_and_respiration/GO-0022402_cell_cycle_genes (1).csv', index_col=0, header=None)\n",
    "cell_respr_genes = pd.read_csv('/home/jovyan/Useful code and scripts/issac_cell_cycle_and_respiration/GO-0045333_cell_respiration (1).csv', index_col=0, header=None)\n",
    "cell_cycle_genes_list = list(cell_cycle_genes.index)\n",
    "cell_respr_genes_list = list(cell_respr_genes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_remove = []\n",
    "\n",
    "for i in objects:\n",
    "    remove = list(i.var.index[i.var_names.str.match(\"HB|MT-|RPS|RPL\")])\n",
    "    list_to_remove = list_to_remove + remove + cell_cycle_genes_list + cell_respr_genes_list\n",
    "    list_to_remove = list(dict.fromkeys(list_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for x in objects:\n",
    "    x = x[:,~x.var_names.isin(list_to_remove)]\n",
    "    name = objects_name[n]\n",
    "    globals()[name] = x\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = [macrophage,erythroid,endoderm]\n",
    "\n",
    "for i in objects:\n",
    "    print('Before pre-processing shape:')\n",
    "    print(i.shape)\n",
    "    #ud.describe_basic(i)\n",
    "    sc.pp.filter_genes(i, min_cells=3)\n",
    "    sc.pp.normalize_total(i)\n",
    "    sc.pp.log1p(i)\n",
    "    sc.pp.highly_variable_genes(i)\n",
    "    print('After pre-processing shape:')\n",
    "    #ud.describe_basic(i)\n",
    "    print(i.shape)\n",
    "    print('Loop complete')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "Object = endoderm\n",
    "key_var = 'early_late_time_points'\n",
    "run_name = 'Endoderm_Early_Late_across_time_DE'\n",
    "save_loc = '/lustre/scratch117/cellgen/team298/SharedFolders/Collab_scripting/GSEA_confusion_mat/Early_late_across_time_outs_20220224'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-training",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(save_loc):\n",
    "    save_loc = save_loc + datetime.date.today().strftime(\"_%I%M_%d%m%Y\")\n",
    "    if not os.path.exists(save_loc):\n",
    "        os.makedirs(save_loc)\n",
    "    adata = sc.read(Object)\n",
    "    adata.var_names_make_unique()\n",
    "    return save_loc, adata\n",
    "\n",
    "def setup2(save_loc):\n",
    "    save_loc = save_loc\n",
    "    adata = Object\n",
    "    adata.var_names_make_unique()\n",
    "    return save_loc, adata\n",
    "\n",
    "def Pre_process(adata,key_var,top_de = 50):\n",
    "    if np.max(adata.X) > 1000:\n",
    "        sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n",
    "        sc.pp.log1p(adata)\n",
    "\n",
    "    spot_var = key_var\n",
    "    DE_name = (save_loc+ '/' + run_name + '_DEGS.csv')\n",
    "    sc.tl.rank_genes_groups(adata, spot_var, method='wilcoxon',n_genes=500)\n",
    "    result = adata.uns['rank_genes_groups']\n",
    "    groups = result['names'].dtype.names\n",
    "\n",
    "    DE = pd.DataFrame(\n",
    "        {group + '_' + key[:1]: result[key][group]\n",
    "        for group in groups for key in ['names', 'pvals','logfoldchanges']}).head(500)\n",
    "    #DE_name =\"./DEGS_gastrulation_211121.csv\"\n",
    "    DE.to_csv(DE_name)\n",
    "    degs = DE[:]\n",
    "#     if 'concat' in locals() or 'concat' in globals():\n",
    "#         del(concat)\n",
    "    n = degs.loc[:, degs.columns.str.endswith(\"_n\")]\n",
    "    n = pd.melt(n)\n",
    "    p = degs.loc[:, degs.columns.str.endswith(\"_p\")]\n",
    "    p = pd.melt(p)\n",
    "    l = degs.loc[:, degs.columns.str.endswith(\"_l\")]\n",
    "    l = pd.melt(l)\n",
    "    n = n.replace(regex=r'_n', value='')\n",
    "    n = n.rename(columns={\"variable\": \"cluster\", \"value\": \"gene\"})\n",
    "    p = (p.drop([\"variable\"],axis = 1)).rename(columns={ \"value\": \"p_val\"})\n",
    "    l = (l.drop([\"variable\"],axis = 1)).rename(columns={ \"value\": \"logfc\"})\n",
    "    # Rank Default DEGs with::\n",
    "    concat = pd.concat([n,p,l],axis=1)\n",
    "    #remove mito genes from data\n",
    "    concat = concat[~concat[\"gene\"].str.startswith(\"MT-\")]\n",
    "    concat = concat[~concat[\"gene\"].str.startswith(\"RP11-\")]\n",
    "    concat[\"cluster\"] = concat[\"cluster\"].astype(str)\n",
    "    marker_df = concat.groupby('cluster').apply(lambda grp: grp.nsmallest(top_de*2, 'p_val')).reset_index(drop=True)\n",
    "    marker_df = marker_df.groupby('cluster').apply(lambda grp: grp.nlargest(top_de, 'logfc')).reset_index(drop=True)\n",
    "    markers = marker_df.groupby('cluster')['gene'].apply(list).to_dict()\n",
    "    markers = dict(sorted(markers.items()))\n",
    "    markers = {str(k):v for k,v in markers.items()}\n",
    "    markers = markers\n",
    "    sc.pl.dotplot(adata, var_names = markers, groupby=spot_var,dendrogram=False,standard_scale='var', color_map='Reds', show = True, save = (run_name + '.pdf'))\n",
    "    return marker_df, markers, adata\n",
    "\n",
    "# Naively submit all DEGs\n",
    "def gseapy_enr(marker_df):\n",
    "    import gseapy\n",
    "    gene_set_names = gseapy.get_library_name(organism='Human')\n",
    "\n",
    "    for i in list(marker_df['cluster'].unique()):\n",
    "        #Available databases : 'Human', 'Mouse', 'Yeast', 'Fly', 'Fish', 'Worm' \n",
    "        import gseapy\n",
    "        gene_set_names = gseapy.get_library_name(organism='Human')\n",
    "        glist = list(marker_df['gene'][marker_df['cluster'].isin([i])])\n",
    "        enr_res = gseapy.enrichr(gene_list=glist,\n",
    "                         organism='Human',\n",
    "                         gene_sets='GO_Biological_Process_2021' ,#'GO_Molecular_Function_2021', #''GO_Biological_Process_2021',\n",
    "                         description='pathway',\n",
    "                         cutoff = 0.05)\n",
    "        enr_res.res2d.to_csv(save_loc + '/'+i+'_enr_res_score.csv')\n",
    "        \n",
    "def generate_cluster_maps():\n",
    "    Gene_set_dict_per_category = {}\n",
    "    gsea_paths = pd.DataFrame(pathlib.Path(save_loc).glob(\"*res_score.csv\"),columns = ['fpaths'])\n",
    "    for gsea_fpath in gsea_paths['fpaths']:\n",
    "        enr_name = str(gsea_fpath).replace(save_loc+'/','')\n",
    "        enr_name = str(enr_name).replace('.csv','')\n",
    "        gsea = pd.read_csv(gsea_fpath,index_col=0)\n",
    "        gsea = gsea[gsea['P-value'] < 0.05]\n",
    "        gsea['g_list'] = 'NAN'\n",
    "        gsea_dict = {}\n",
    "        for z in gsea.index:\n",
    "            term = (gsea['Term'][gsea.index==z].item())\n",
    "            gsea_dict[term] = (gsea.loc[gsea.index == z ,'Genes'][z]).split(\";\")\n",
    "            if len(gsea_dict[term]) >= min_term:\n",
    "                gsea.at[z,'g_list'] = gsea_dict[term]\n",
    "        rows_to_remove = list(gsea.index[gsea['g_list']== 'NAN'])\n",
    "        gsea = gsea[~gsea.index.isin(rows_to_remove)]\n",
    "        unique_genes = list(np.unique(np.array([item for sublist in gsea['g_list'].values for item in sublist])))\n",
    "        gseapy_matrix = pd.DataFrame(columns=gsea.Term.unique(), index=unique_genes)\n",
    "        for col in gseapy_matrix.columns:\n",
    "            for index in gseapy_matrix.index:\n",
    "                if index in gsea_dict[col]:\n",
    "                    gseapy_matrix.at[index,col] = 1 # this is not a clean way to do this // rewrite\n",
    "                else:\n",
    "                    gseapy_matrix.at[index,col] = 0 # this is not a clean way to do this // rewrite\n",
    "        for i in gseapy_matrix.columns:\n",
    "            gseapy_matrix[i] = gseapy_matrix[i].astype('int')\n",
    "        # future updte Let's use PPI matrix instead of corr as this gives better predictive value\n",
    "        # corr_table = pps.matrix(gseapy_matrix)\n",
    "        # corr_table = corr_table.pivot(columns='x', index='y', values='ppscore')\n",
    "        corr_table = gseapy_matrix.corr()\n",
    "        \n",
    "        # simple clustermap just on corr_table\n",
    "        cm = sns.clustermap(corr_table, figsize=(30,30))\n",
    "        plt.setp(cm.ax_heatmap.xaxis.get_majorticklabels(), fontsize=20)\n",
    "        plt.setp(cm.ax_heatmap.yaxis.get_majorticklabels(), fontsize=20)\n",
    "        plt.title(enr_name)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Neighbourhoods clustergram\n",
    "        pca = PCA(n_components=int(len(gsea)/2))\n",
    "        pca.fit(corr_table)\n",
    "        X_pca = pca.transform(corr_table)\n",
    "        X = X_pca\n",
    "        y = pd.DataFrame(X_pca).index\n",
    "        sil_score = []\n",
    "        n_clust = [] \n",
    "        models = {}\n",
    "        if len(gsea) < 10:\n",
    "            for n_cluster in range(2, len(gsea)):\n",
    "                kmeans = KMeans(n_clusters=n_cluster).fit(X)\n",
    "                models[n_cluster] = kmeans\n",
    "                label = kmeans.labels_\n",
    "                sil_coeff = silhouette_score(X, label, metric='euclidean')\n",
    "                n_clust.append(n_cluster)\n",
    "                sil_score.append(sil_coeff)\n",
    "        else:\n",
    "            for n_cluster in range(2, 11):\n",
    "                kmeans = KMeans(n_clusters=n_cluster).fit(X)\n",
    "                models[n_cluster] = kmeans\n",
    "                label = kmeans.labels_\n",
    "                sil_coeff = silhouette_score(X, label, metric='euclidean')\n",
    "                n_clust.append(n_cluster)\n",
    "                sil_score.append(sil_coeff)\n",
    "                \n",
    "        kneedle = KneeLocator(x = sil_score, y = n_clust, S=0.01, curve=\"convex\", direction=\"increasing\")\n",
    "        model = models[n_clust[sil_score.index(kneedle.knee)]]\n",
    "        pred_clusters = model.predict(X)\n",
    "        figure, ax = plt.subplots(figsize=(5, 5))\n",
    "        ax = plt.scatter(X[:,0], X[:,1], c=pred_clusters)\n",
    "        plt.legend(handles=ax.legend_elements()[0], labels=list(set(pred_clusters)), bbox_to_anchor=(1.05, 1))\n",
    "        plt.title(enr_name)\n",
    "        gsea['k_clust'] = pred_clusters\n",
    "        gsea = gsea.sort_values(by=['k_clust'])\n",
    "        \n",
    "        #Filter junk clusters\n",
    "        ranker = pd.DataFrame(gsea.groupby('k_clust').count().iloc[:,0]).sort_values(pd.DataFrame(gsea.groupby('k_clust').count().iloc[:,0]).columns[0],ascending=False).head(5)\n",
    "        gsea = gsea[gsea['k_clust'].isin(ranker.index)]\n",
    "        corr_table = corr_table[corr_table.index.isin(gsea['Term'])]\n",
    "        corr_table = corr_table[(gsea['Term'])]\n",
    "        corr_table = corr_table.reindex(list(gsea['Term']))\n",
    "        corr_table = corr_table[list(gsea['Term'])]\n",
    "        corr_table_organised = corr_table[:]\n",
    "        corr_table_organised.index = 'clus_'+ gsea['k_clust'].astype(str)+ '_' +corr_table_organised.index.astype(str) \n",
    "        \n",
    "        pal =sns.color_palette(\"magma\", as_cmap=True)# sns.diverging_palette(10, 240, n=20)\n",
    "        figure, ax = plt.subplots(figsize=(30, 30))\n",
    "        ax = sns.heatmap(corr_table_organised, annot=False,vmin=min(np.min(corr_table)), vmax=1, linewidths=1, center=np.median(np.min(corr_table)), square=True, annot_kws={\"size\": 16}) # font size\n",
    "        ax.set_title(enr_name)\n",
    "        figure.savefig((save_loc+'/'+enr_name+'_corr_plot.pdf'),bbox_inches='tight',dpi=300)  \n",
    "        gsea.to_csv(save_loc+'/'+enr_name+'_enr_score_k_clust.csv')\n",
    "        corr_table_organised.to_csv(save_loc+'/'+enr_name+'_corr.csv')\n",
    "        \n",
    "        # Dictionary\n",
    "        dict_name = enr_name.replace('res_score','clust_dict')\n",
    "        key_name = enr_name.replace('res_score','')\n",
    "        Gene_set_clust_dict = {}\n",
    "        \n",
    "        for clust in gsea['k_clust'].unique():\n",
    "            key = key_name + 'Gene_set_' + str(clust)\n",
    "            subset = gsea[gsea['k_clust'].isin([clust])]\n",
    "            values = []\n",
    "            for index in subset.index:\n",
    "                genes = (subset.loc[subset.index == index ,'Genes'][index]).split(\";\")\n",
    "                [values.append(gene) for gene in genes if gene not in values]\n",
    "            Gene_set_clust_dict[key] = values\n",
    "        globals()[dict_name] = Gene_set_clust_dict # Returns individual dictionary for the category e.g. if category = 'Early': Early_enr_clust_dict\n",
    "        Gene_set_dict_per_category.update(Gene_set_clust_dict)\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(save_loc)\n",
    "    sc.pl.dotplot(adata, Gene_set_dict_per_category, groupby=key_var, use_raw=False, standard_scale='var', save='gseapy_geneset_overall_cluster_dotplot.pdf')\n",
    "    os.chdir(cwd)\n",
    "    globals()['Gene_set_dict_per_category'] = Gene_set_dict_per_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_de = 15\n",
    "save_loc, adata = setup2(save_loc)\n",
    "marker_df, markers, adata = Pre_process(adata,key_var, top_de = top_de)\n",
    "gseapy_enr(marker_df)\n",
    "min_term = 2\n",
    "generate_cluster_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "endoderm2 = endoderm2[~endoderm2.obs['nhood_Sig_FC'].str.contains('False')]\n",
    "sc.pp.scale(endoderm2, zero_center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict = {\n",
    "\n",
    "'Fibrinogen_and_cross_linking': ['FGB','FGG','FGA'],\n",
    "\n",
    "'Retinoid_metabolic_process': ['RBP4','RBP2',  'RBP3', 'RARRES2'],  \n",
    "    \n",
    "'Lipid metabolic processes':['APOM','APOB','ALB','FABP1','FASN', 'CYP51A1','LSS','GPAM','SREBF1',],\n",
    " \n",
    "'Regulation of apoptotic process': ['NFKBIA','JUN','ATF3',],\n",
    "    \n",
    "}\n",
    "\n",
    "sc.pl.matrixplot(endoderm2, var_names=plot_dict, use_raw=False, groupby='early_late_time_points', vmax=1, vmin=-1, cmap='RdBu_r', save='early_late_degs_cut_20220323.pdf', colorbar_title='mean z-score',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_env_Hlab",
   "language": "python",
   "name": "python_env_hlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
